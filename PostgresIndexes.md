# [Андрей Сальников — Индексы в PostgreSQL. Как понять, что создавать](https://youtu.be/ju9F8OvnL4E?si=49VWlAV0PrMY_Osj)


## Плюсы индексов:

* Легальный костыль для ускорения поиска

## Минусы индексов:

* Замедление записи в таблицы (реляционки подходят для OLTP Нагрузки 80% чтения, 20% записи)
* Могут занимать внушительные объемы на диске. Если сумма размеров всех индексов до 50% размера таблицы - все ок, если
  нет - чето идет не так
* Усложненное техническое обслуживание - индексы пухнут и вакуум на них не так хорошо работает. Особенно на часто
  изменяемых данных
* Индекс может сделать хуже

## Чеклист создания индекса:

- Ориентироваться только на прод
- Обладать статистикой нагрузки на БД от запросов ( долгий запрос не всегда плохой запрос. Плохой запрос может быть
  быстрым, но частым и не оптимизированным)
    * pg_stat_statements - хорошо
    * pgBadger - с осторожностью (парсер логов постгреса) - проблема может быть в том, что не все запросы логируются (
      супербыстрые могут не логироваться)
- Иметь примеры запросов с параметрами
    * для понимания входящих параметров запроса
    * необходимо для проверки
- Уметь читать статистику распределения данных (планировщик). Есть планировщик и екзекутор. Планировщик строит свой
  выбор на статистике
- Представление pg_stats.
  Важные колонки:
    * уникальность значений в колонке n_distinct
    * упорядоченность значений: сorrelation
    * объемы null: null_frac
    * Частые значения: most_common_vals и most_common_freqs
- Вручную собрать более полную статистику (в постгресе берется sample в 30k строк (можно менять для всего инстанса или
  конкретной таблицы)). Юзать если есть ощущения что в статистике есть существенные промахи

## Типы индексов

* **btree** - наиболее старый тип индексов и самый распространенный
    * Наиболее распространенный тип индексов
    * алгоритмы работы и модель хранения улучшаются
    * покрывает 90% задач
    * Легко создать ориентируясь на статистику по таблице
* **hash**
    * бесполезен, btree работает быстрее в общих случаях
    * сделан потому что Hash занимает меньше места чем btree индекс, раньше было ограничение
    * обслуживает только операцию равенства, когда btree может обслуживать операцию сравнения и равенства
* **gist** - позволяет решать задачи типа Расстояние, площадь, перекрытие
    * в чистом виде полезен для геоданных
    * есть расширения
        * pg_trgm - позволяет индексировать запросы по подстроке like, ilike, ~ ,~* (regexp)
        * btree_gist - сложные constraints с интервалами (задача создания расписаний, чтобы расписания не пересекались)
* **sp_gist**
    * практических применений в oltp нет
* **gin**
    * не сильно радует dba (может просадить диск буффером), могут быть долгие коммиты
    * хорош для текстового поиска (+ pg_tgrm )
    * нужен для поиска по jsonb. Есть два оператора
        * jsonb_ops - индексирует все что есть в json и по нему можно искать любое значение в json. Может быть просто
          огромным
        * jsonb_path_ops - заточен на поиск путей в жсон, размер меньше
* **brin** - когда данных много и они упорядоченны движки бд почти всегда достают данные блоками.
  Мы можем проиндексировать только наименьшее и наибольшее значение блока
    * Крайне компактный индекс
    * Работает быстро
    * Но мы не всегда уверенны, что значение есть в блоке (его может просто не быть в бд вообще)

## Indexes null or not null

Пререквизиты:
таблица public.pgconf, rows count 10_000_000

| Column     | TYPE                    | Collation | Nullable | Default |
|------------|-------------------------|-----------|----------|---------|
| id         | bigint                  |           | Not null |         |
| fk_id      | bigint                  |           |          |         |
| state      | text                    |           |          |         |
| amount     | numeric                 |           |          |         |
| item       | text                    |           |          |         |
| created_at | timestamp with timezone |           |          |         |

Indexes:
pgconf_pkey PRIMARY KEY, btree(id)

FK constraints:
pgconf_fk_id_fkey FOREIGN KEY (fk_id) REFERENCES pgconf(id)

Size pgconf 816 MB.
Size pgconf_pkey 214 MB

Удалим строку:\
`delete from pgconf where id = 10;`

_Delete on pgconf\
-> Index Scan using pgconf_pkey on pgconf\
Index Cond: (id = 10)\
Planning Time: 0.043 ms\
**Trigger for constraint pgconf_fk_id_fkey: time=690.455 calls=1**\
Execution Time: **690.515 ms**_

Самое долгое время занимает поиск по constraint. Даже с двумя worker очень долго.
Запрос не долгий, небольшой, может непопасть в логи, и очень неоптимальный.

Под капотом будет:

`select * from pgconf where fk_id = 10;`\
Gather\
Workers Planned: 2\
Workers Launched: 2\
-> **Parallel Seq Scan on pgconf**\
Filter: (fk_id = 10)\
Rows Removed by Filter: 3333333\
Planning Time: 0.059 ms\
Execution Time: 281.468 ms\

Для FK лучше создавать индекс, чтобы всякие проверки работали быстро.  
Работать станет быстрее. Но можно пойти дальше -> зайдем в табличку pg_stats

select * from pg_stats where tablename = 'pgconf' and attname = 'fk_id';\

|                   |                | 
|-------------------|----------------| 
| tablename         | pgconf         | 
| attname           | fk_id          | 
| null_frac         | **0.92943335** |  
| n_distinct        | -0.070566654   | 
| most_common_vals  | null           | 
| most_common_freqs | null           | 
| correlation       | 0.0095442245   | 

Почти 93 процента пустых значений. Остальные поля по данным не важны при таком кол-ве нуллов.
Попробуем улучшить индекс, добавим условие nonnull. Сделаем частичный индекс.
` create index fk_not_null on pgconf (fk_id) where fk_id is not null; `\
Не ускорит запрос, но существенно сохранит место на диске

Но этот индекс будет прекрасно работать на запросе по равенству или неравенству (PG сам поймет, что мы ищем non null
значения).
В общем случае данный индекс будет применяться, когда в запросе есть условие аналогичное или приводимое к условию
частичного индекса.

`select * from pgconf where fk_id = 10;`
**Index Scan using fk_not_null** on pgconf
Index Cond: (fk_id = 10)
Planning Time: 0.080 ms
Execution Time: 0.027 ms

### Результаты

Time: 690.713 ms vs 0.336 ms
**Ускорение в 2055 раз!**
pgconf_pkey : 214 MB
fk : 215 MB
fk_not_null : 15 MB
**Уменьшение размеров в 14 раз!**

## Null или дефолт на старых строках при создании колонки

PG в новых версиях не будет апдейтить все строки.  
Просто в метаданных будет отмечено, что все строки до определенной транзакции будут иметь такое значение колонки.

## Indexes partial

Пример: поиск необработанных событий  
`select * from pgconf where state = 'ожидает' order by created_at limit 100;`

План такого запроса будет:  
_Limit
-> Gather Merge  
Workers Planned: 2  
Workers Launched: 2  
-> Sort  
Sort Key: created_at  
Sort Method: top-N heapsort Memory: 35kB  
Worker 0: Sort Method: top-N heapsort Memory: 35kB  
Worker 1: Sort Method: top-N heapsort Memory: 35kB  
-> Parallel Seq Scan on pgconf  
Filter: (state = 'ожидает'::text)  
Rows Removed by Filter: 3003483  
Planning Time: 0.140 ms  
**Execution Time: 362.268 ms**_

Для OLTP нагрузки нельзя включать параллельное исполнение, так быстро, насколько мы можем.  
Если нам надо параллелиться - значит мы забираем у второго запроса забираем время исполнения. Параллельность только для
OLAP

`create index strange on pgconf ((state = 'ожидает'))`  
такой индекс по сути индексирует результат сравнения, не является частичным и не будет использоваться!

`create index normal on pgconf (created_at, state)`
Такой индекс будет работать и использоваться в плане выполнения

Если взглянуть на статистику то увидим:

|                   |                                         |
|-------------------|-----------------------------------------|
| attname           | created_at                              |
| **null_frac**     | **0**                                   |
| n_distinct        | -0.4638518                              |
| most_common_vals  |                                         |
| most_common_freqs |                                         |
| histogram_bounds  | {"2021-10-23 00:16:35.571674+03”, …, …} |
| **correlation**   | **1**                                   |

null - нету, correlation = 1 -> данные упорядоченны

|                       |                                    |
|-----------------------|------------------------------------|
| attname               | state                              |
| null_frac             | 0                                  |
| n_distinct            | 3                                  |
| **most_common_vals**  | **{обработано,ожидает,ошибка}**    |
| **most_common_freqs** | **{0.89863336,0.09996667,0.0014}** |
| correlation           | 0.81656545                         |

state - неравномерно распределено, большинство стейтов - обработано. Скорее всего мы будем обрабатывать ожидает и
ошибка.  
Лучше создать частичный индекс

`create index perfect on pgconf (created_at) where state != 'обработано';`

Limit  
-> Index Scan using perfect on pgconf  
Filter: (state = 'ожидает'::text)  
Rows Removed by Filter: 2  
Planning Time: 0.120 ms  
**Execution Time: 0.105 ms**

### Результаты:

Time: 690.713 ms vs 0.105 ms  
**Ускорение в 3450 раз!**

pgconf_pkey : 214 MB  
strange : 215 MB  
normal : 464 MB <-  
perfect : 21 MB <-  
**Уменьшение размеров в 22 раза!**

Причем если поставить первым полем в индексе state, то индекс будет отрабатывать так же быстро, но займет **466 MB**!
`create index expected on pgconf (state, created_at);`
Limit
-> Index Scan using expected on pgconf
Index Cond: (state = 'ожидает'::text)
Planning Time: 0.087 ms
Execution Time: 0.112 ms

Такой размер происходит из-за того, что created_at - более равномерно размазано по btree, чем state.

В примере с индексом `create index perfect on pgconf (created_at) where state != 'обработано';` мы не добавили state в
индексированное поле.  
Это не обязательно при малом количестве возможных значений и небольшом индексе. Но для ускорения вычитки и при большом
кол-ве вариантов значений стоит добавить в индексированные поля.

# Indexes Когда очень, очень нужно.

Если небольшой продукт и нужно аналитику показывать онлайн. Обычно для таких задач подходят колоночные базы данных.

`select sum (amount) from pgconf  
where state = 'обработано'
and item = 'апельсин'
and created_at between '2021-10-23 00:00'
and '2021-10-24 00:00';
`

Мы как разработчики можем предложить предрасчитанный агрегат за все время, обновляемый раз в сутки и считаемый ночью.  
А горячие данные можно предложить за мелкий промежуток времени

Finalize Aggregate  
-> Partial Aggregate  
-> Parallel Seq Scan on pgconf  
Filter: ((created_at >= '2021-10-23 00:00') AND  
(created_at <= '2021-10-24 00:00') AND  
(state = 'обработано'::text) AND  
(item = 'апельсин'::text))  
Rows Removed by Filter: 3323792  
Planning Time: 0.087 ms  
**Execution Time: 357.851 ms**

Посмотрим на статистику

|                   |                                |
|-------------------|--------------------------------|
| attname           | state                          |
| null_frac         | 0                              |
| n_distinct        | 3                              |
| most_common_vals  | {обработано,ожидает,ошибка}    |
| most_common_freqs | {0.89863336,0.09996667,0.0014} |
| correlation       | 0.81656545                     |

|                   |                                                        |
|-------------------|--------------------------------------------------------|
| attname           | item                                                   |
| null_frac         | 0                                                      |
| n_distinct        | 5                                                      |
| most_common_vals  | **{дыня,тыква,апельсин, яблоко,персик}**               |
| most_common_freqs | **{0.59943336,0.27633333, 0.0994,0.022,0.0028333333}** |
| correlation       | 0.44420442                                             |

Разделены неравномерно, но их не много. Из индекса особо ничего не выкинешь. Радует что нет нуллов.

Хороший индекс:
`create index normal on pgconf (created_at, item);`

Aggregate  
-> Index Scan using normal on pgconf  
Index Cond: ((created_at >= '2021-10-23 00:00') AND  
(created_at <= '2021-10-24 00:00') AND  
(item = 'апельсин'::text))  
Filter: (state = 'обработано'::text)  
Rows Removed by Filter: 3122  
Planning Time: 0.124 ms  
**Execution Time: 32.788 ms**  

Хороший он потому, что если делать индекс по state - то все равно почти вся таблица будет, по этому берем сначала created_at, потом item.

Есть функция include для таких задач

`create index special on pgconf (created_at, item) include (amount) where state = 'обработано';`
state добавляем чтобы был index only scan 

Aggregate  
-> Index Only Scan using special on pgconf  
Index Cond: ((created_at >= '2021-10-23 00:00') AND  
(created_at <= '2021-10-24 00:00') AND  
(item = 'апельсин'::text))  
Heap Fetches: 28624  
Planning Time: 0.144 ms  
**Execution Time: 30.084 ms**  

### Результаты:

Time: 357.851 ms vs 30.084 ms  
**Ускорение в 11 раз!**  
pgconf_pkey : 214 MB  
normal : 395 MB  
special : 379 MB  
**Special хоть и перегружен, но меньшего размера.**  

# Вопросы после доклада
## Порядок колонок в индексе
Нужно понимать какие запросы прилетают в таблицу.  
Наиболее селективное поле - поле с наибольшим кол-вом уникальных значени й.
Если нужно починить на горячую - опираемся на статистику и выбираем самые селективные поля, чтобы получилось гармоничное дерево

## Советы по жизни
* Если есть FK - покрывайте его индексами
* Старайтесь подумать, много ли пустых значений -> добавляйте в индекс условие NotNull
* При создании индекса ориентируйтесь на запросы, на частые условия фильтра в запросах
* Составной индекс для трех полей это норм, но больше трех - чет не то 
* Репа с полезными скриптами https://github.com/dataegret/pg-utils 
  * index_bloat - Распухшие индексы
  * indexes_with_null - индексы на полях где много null, можно пересоздать как частичные 
  * top_tables - размер табличек и индексов по этим таблицам
  * redundant_indexes
  * low_used_indexes - индексы, которые мало читались

## Сколько индексов можно всего? 

1) В первую очередь смотрим соотношение размера таблицы и индекса. Таблица в 50ГБ, если индексов на 150ГБ -> значит туда лепили все подряд.
2) Смотрим статистику чтения по индексам. Если индекс читается, но мало, можно сбросить статистику и помониторить неделю/месяц. Скорее всего по этим индексам чтения не будет.
3) Можно смотреть на то как созданы индексы. Индексы по нескольким полям -> селективное должно быть первым. 
4) Если есть индекс `index on (timestamp, state)` и `index on (timestamp)` - второй можно удалить, первый закроет такую выборку. Работает для индексов по двум и трем полям, если первые поля одинаковые




